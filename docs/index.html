--- 
layout: mainpage
---


This is the main page of our project exploring the use of adversarial examples which are inputs with slight modifications that mislead neural networks to give incorrect outputs. 
We review selected references to present the current state of research of that topic.

To learn more about how they work we implement selected attack methods in Jupter notebooks and explain the steps.
We then compare the effectiveness of these attacks in the <a href="{{ site.baseurl | prepend: site.url | relative_url }}{% link _pages/03_Results.md %}">Results</a> section.
